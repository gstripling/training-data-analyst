{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Feature Engineering in Keras.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rNdWfPXCjTjY"
      },
      "source": [
        "# LAB 01:  Basic Feature Engineering in Keras \n",
        "\n",
        "**Learning Objectives**\n",
        "\n",
        "* Setup up the environment\n",
        "* Create the project datasets\n",
        "* Create an input pipeline using tf.data\n",
        "* Build, train, and evaluate a model using Keras\n",
        "* Feature engineer categorical and numeric features \n",
        "* Load and preprocess test data\n",
        "* Create and test a prediction model\n",
        "\n",
        "\n",
        "## Introduction \n",
        "In this lab, we utilize feature engineering to improve the prediction of housing prices.  We will use Keras to build a housing price prediction model, using feature engineering to improve model prediciton.  \n",
        "\n",
        "Each learning objective will correspond to a __#TODO__ in this student lab notebook -- try to complete this notebook first and then review the [solution notebook](../solution/feateng-solution_bqml.ipynb). **NOTE TO SELF**:  UPDATE HYPERLINK. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JpbVY_UrqQO",
        "colab_type": "text"
      },
      "source": [
        "### Set up environment variables and load necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV1ZN7ggr6gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "export PROJECT=$(gcloud config list project --format \"value(core.project)\")\n",
        "echo \"Your current GCP Project Name is: \"$PROJECT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWya0VU1r6sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "PROJECT = \"cloud-training-demos\" # REPLACE WITH YOUR PROJECT NAME\n",
        "REGION = \"us-west1-b\" # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
        "\n",
        "# Do not change these\n",
        "os.environ[\"PROJECT\"] = PROJECT\n",
        "os.environ[\"REGION\"] = REGION\n",
        "os.environ[\"BUCKET\"] = PROJECT # DEFAULT BUCKET WILL BE PROJECT ID\n",
        "\n",
        "if PROJECT == \"your-gcp-project-here\":\n",
        "  print(\"Don't forget to update your PROJECT name! Currently:\", PROJECT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VxyBFc_kKazA"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LuOWVJBz8a6G",
        "colab": {}
      },
      "source": [
        "!pip install sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9dEreb4QKizj",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils import plot_model\n",
        "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSE5jbCf9eec",
        "colab_type": "text"
      },
      "source": [
        "# PART 1:  Set-Up!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv0A5SlBeW18",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **REVIEW and THEN RUN** all cells in Part 1. This helps us get the data, validate data pre-processing and ensure that the data is ready for the neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndTs2oTUssGH",
        "colab_type": "text"
      },
      "source": [
        "## The Source Dataset\n",
        "\n",
        "The California housing dataset data contains 20,640 observations on 10 variables.  The data has been pre-processed so that there are no missing values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM6-n6xntv3t",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the query to create a Pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REZ57BXCLdfG",
        "colab": {}
      },
      "source": [
        "#NOTE TO Lab Reviewers: Lab requires students to clone the training-data-analyst repo in the Qwiklab portion,\n",
        "\n",
        "dataframe = pd.read_csv('housing_pre-proc.csv', error_bad_lines=False)\n",
        "dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieimDrzpxfe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#See datatype for each feature\n",
        "\n",
        "dataframe.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ySDIORqmd77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check for null values\n",
        "\n",
        "dataframe.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u0zhLtQqMPem"
      },
      "source": [
        "####  Split the dataset for ML\n",
        "\n",
        "The dataset we loaded was a single CSV file. We will split this into train, validation, and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YEOpw7LhMYsI",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(dataframe, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFz_dsZ2-Cxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Print out the output.  \n",
        "\n",
        "print(\"\\nTrain:\\n\")\n",
        "print(train.head())\n",
        "print(train.shape)\n",
        "\n",
        "print(\"\\nValidati:\\n\")\n",
        "print(val.head())\n",
        "print(val.shape)\n",
        "\n",
        "print(\"\\nTest:\\n\")\n",
        "print(test.head())\n",
        "print(test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz9kfjOMBX9U",
        "colab_type": "text"
      },
      "source": [
        "Now, we need to output the split files.  We will specifically need the test.csv later for testing.  You should see the files appear in the home directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADX23QUu_Wiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv('train.csv', encoding='utf-8', index=False)\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU1FgmKEAmWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val.to_csv('val.csv', encoding='utf-8', index=False)\n",
        "val.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvUNWv9iBMFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_csv('test.csv', encoding='utf-8', index=False)\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5FAZwwn_rbX",
        "colab_type": "text"
      },
      "source": [
        "# Part 2:  Your feature engineering lab starts here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj35eYy_lutI",
        "colab_type": "text"
      },
      "source": [
        "## Objective:   Build an input pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84ef46LXMfvu"
      },
      "source": [
        "#### **Exercise**:   Create an input pipeline using tf.data\n",
        "\n",
        "Next, we will wrap the dataframes with [tf.data](https://www.tensorflow.org/guide/datasets). This will enable us  to use feature columns as a bridge to map from the columns in the Pandas dataframe to features used to train the model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V08sqkMr_64P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO: This function is missing two lines.  Correct and run the cell.\n",
        "\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NkcaMYP-MsRe",
        "colab": {}
      },
      "source": [
        "# SOLUTION\n",
        "#A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('median_house_value')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtTJZeyzAszs",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the cell to initialize the training datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CXbbXkJvMy34",
        "colab": {}
      },
      "source": [
        "batch_size = 32 \n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qRLGSMDzM-dl"
      },
      "source": [
        "## Understand the input pipeline\n",
        "\n",
        "Now that we have created the input pipeline, let's call it to see the format of the data it returns. We have used a small batch size to keep the output readable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSyRhEJuA9e2",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the cell to see a sample of the features from the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CSBo3dUVNFc9",
        "colab": {}
      },
      "source": [
        "for feature_batch, label_batch in train_ds.take(1):\n",
        "  print('Every feature:', list(feature_batch.keys()))\n",
        "  print('A batch of households:', feature_batch['households'])\n",
        "  print('A batch of ocean_proximity:', feature_batch['ocean_proximity'])\n",
        "  print('A batch of targets:', label_batch )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OT5N6Se-NQsC"
      },
      "source": [
        "We can see that the dataset returns a dictionary of column names (from the dataframe) that map to column values from rows in the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEGEAqaziwfC",
        "colab_type": "text"
      },
      "source": [
        "### Numeric columns\n",
        "The output of a feature column becomes the input to the model. A numeric is the simplest type of column. It is used to represent real valued features. When using this column, your model will receive the column value from the dataframe unchanged.\n",
        "\n",
        "In the California housing prices dataset, most columns from the dataframe are numeric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jioIeb9lBGNN",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   Create a variable called **num_c** to hold only the numerical feature columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVZG1vvGBVdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyXRsEgIEbSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "num_c = ['longitude',  'latitude',\n",
        "                'housing_median_age', 'total_rooms', 'total_bedrooms',\n",
        "                 'population', 'households', 'median_income']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwMEcH_52JT8",
        "colab_type": "text"
      },
      "source": [
        "### Scaler function\n",
        "It is very important for numerical variables to get scaled before they are \"fed\" into the neural network. Here we use min-max scaling. Here we are creating a function named 'get_scal' which takes list of numerical features and  returns 'minmax' function, which will be used in tf.feature_column.numeric_column() as normalizer_fn in parameters. 'minmax' function itself takes a 'numerical' number from a particular feature and return scaled value of that number. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig1k5ovWBnN8",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the next two cells to scale the numeric features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGnpUKg4lc4m",
        "colab": {}
      },
      "source": [
        "#Scalardef get_scal(feature):\n",
        "def get_scal(feature):\n",
        "  def minmax(x):\n",
        "    mini = train[feature].min()\n",
        "    maxi = train[feature].max()\n",
        "    return (x - mini)/(maxi-mini)\n",
        "  return(minmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8IUfcuVaS_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_columns = []\n",
        "for header in num_c:\n",
        "  scal_input_fn = get_scal(header)\n",
        "  feature_columns.append(feature_column.numeric_column(header, normalizer_fn=scal_input_fn))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v9XoD7WCKRM",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the cell to see the total number of feature columns.  Compare this number to the number of numeric features you input earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jgPFThi50sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Total number of feature coLumns: ',len(feature_columns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ug3hB8Sl0jO",
        "colab_type": "text"
      },
      "source": [
        "## Objective:  Build, train, and evaluate a model using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bBx4Xu0eTXWq"
      },
      "source": [
        "#### **Exercise**:   Correct the cell below that creates, compiles, and fits a Keras model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x-gHsiEkAhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO - CODE IS INCORECT \n",
        "#Model create\n",
        "tf.keras.layers.DenseFeatures(feature_columns) = feature_layer \n",
        "\n",
        "tf.keras.Sequential  = model([\n",
        "  feature_layer,\n",
        "  layers.Dense(12,  input_dim=8, activation='relu'),\n",
        "  layers.Dense(8, activation='relu'),\n",
        "  layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "### Model compile\n",
        "model.fit(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['mse']) \n",
        "\n",
        "### Model Fit\n",
        "history = model.compile(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_YJPPb3xTPeZ",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "#Model create\n",
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  layers.Dense(12,  input_dim=8, activation='relu'),\n",
        "  layers.Dense(8, activation='relu'),\n",
        "  layers.Dense(1, activation='linear',  name='median_house_value')\n",
        "])\n",
        "\n",
        "### Model compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['mse']) \n",
        "\n",
        "### Model Fit\n",
        "history = model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSstMnHHh33R",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the cell to show loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo7hhkPqm6Jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "252EPxGp7-FJ",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the model loss curve\n",
        "\n",
        "Next, we will use matplotlib to draw the model's loss curves for training and validation.  A line plot is also created showing the mean squared error loss over the training epochs for both the train (blue) and test (orange) sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n92_zRprDSVs",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the cell to show the the models loss curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7pVC0E07YkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot\n",
        "import matplotlib.pyplot as plt\n",
        "nrows = 1\n",
        "ncols = 2\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "for idx, key in enumerate(['loss', 'mse']):  \n",
        "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
        "    plt.plot(history.history[key])\n",
        "    plt.plot(history.history['val_{}'.format(key)])\n",
        "    plt.title('model {}'.format(key))\n",
        "    plt.ylabel(key)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqkozY268xi7",
        "colab_type": "text"
      },
      "source": [
        "## Objective:  Load and preprocess test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf4TyVJ_Dzxe",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   In the next two cells, read in the test.csv file and validate that there are no null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrHfGGgZDoMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO  YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4C4BmhV8ch9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "test_data = pd.read_csv('test.csv')\n",
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4oAiylWECq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVH2Ma22Cd31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "#No null values.\n",
        "test_data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY2Yrt8fC7RW",
        "colab_type": "text"
      },
      "source": [
        "## Input function for test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAyMaZOlERdF",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the cells to create the input function for the test data and to initialize the test_predict variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rMdDeGDCwpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_input_fn(features, batch_size=256):\n",
        "    \"\"\"An input function for prediction.\"\"\"\n",
        "    # Convert the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qflwLiz9IeZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predict = test_input_fn(dict(test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5SkINtbDIdr",
        "colab_type": "text"
      },
      "source": [
        "## Prediction:  Linear Regression\n",
        "\n",
        "To predict with Keras, you simply call [model.predict()](https://keras.io/models/model/#predict) and pass in the housing features you want to predict the median_house_value for. Note:  We are predicting the model locally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP5NOK8QEma7",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the cell to create the median house value prediction on the test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNc6TSoJDL7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_median_house_value=model.predict(test_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFXK1SKPDYgD",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:  Write a prediction DataFrame for a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RtD5Wm2E4N-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO YOUR CODE HERE.  HINT:  Copy the first line from the test.csv you read in earlier."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xepss0vhoHge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prediction model:  Pass in the features from one row of the test data.\n",
        "\n",
        "#This example shows median house value of $117,800 for INLAND property.\n",
        "\n",
        "#Copy of first line from my test.csv:  Note, do not include the median house value ($117,800), \n",
        "#that is what we are trying to predict.\n",
        "\n",
        "#-121.86\t39.78\t12.0\t7653.0\t1578.0\t3628.0\t1494.0\t3.0905\t117800.0\tINLAND\n",
        "\n",
        "model.predict({\n",
        "    'longitude': tf.convert_to_tensor([-121.86]),\n",
        "    'latitude': tf.convert_to_tensor([39.78]),\n",
        "    'housing_median_age': tf.convert_to_tensor([12.0]), \t\t\n",
        "    'total_rooms': tf.convert_to_tensor([7653.0]),\n",
        "    'total_bedrooms': tf.convert_to_tensor([1578.0]),  \n",
        "    'population': tf.convert_to_tensor([3628.0]),\n",
        "    'households': tf.convert_to_tensor([1494.0]),\t\n",
        "    'median_income': tf.convert_to_tensor([3.0905]),\n",
        "    'ocean_proximity': tf.convert_to_tensor(['INLAND'])\n",
        "    \n",
        "}, steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPssm8p4EZHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "#Prediction model:  Pass in the features from one row of the test data.\n",
        "\n",
        "model.predict({\n",
        "    'longitude': tf.convert_to_tensor([-122.43]),\n",
        "    'latitude': tf.convert_to_tensor([37.63]),\n",
        "    'housing_median_age': tf.convert_to_tensor([34.0]), \t\t\n",
        "    'total_rooms': tf.convert_to_tensor([4135.0]),\n",
        "    'total_bedrooms': tf.convert_to_tensor([687.0]),  \n",
        "    'population': tf.convert_to_tensor([2154.0]),\n",
        "    'households': tf.convert_to_tensor([742.0\t]),\t\n",
        "    'median_income': tf.convert_to_tensor([4.9732]),\n",
        "    'ocean_proximity': tf.convert_to_tensor(['NEAR OCEAN'])\n",
        "    \n",
        "}, steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txl-MRuLFE_8",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:  Analysis\n",
        "\n",
        "The array returns a predicted value.  What does this number mean?  Let's compare this value to the test set.   \n",
        "\n",
        "Go to the test.csv you read in a few cells up.  Locate the first line and find the median_house_value - which should be 249,000 dollars near the ocean. What value did your model predicted for the median_house_value? Was it a solid model performance? Let's see if we can improve this a bit with feature engineering!  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7fFruEWU08C",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78F1XH1Qwvbt",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   Create a cell that indicates which features will be used in the model.\n",
        "\n",
        "Note:  Be sure to bucketize 'housing_median_age' and ensure that 'ocean_proximity' is one-hot encoded.  And, don't forget your numeric values!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv5pbi6kxT-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO - YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxSatLUxUmvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "num_c = ['longitude',  'latitude',\n",
        "                'housing_median_age', 'total_rooms', 'total_bedrooms', \n",
        "                 'households','population', 'median_income']\n",
        "\n",
        "bucket_c = ['housing_median_age']\n",
        "\n",
        "#categorical features\n",
        "cat_i_c = ['ocean_proximity'] #indicator columns\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HbypkYHxxwt",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the next two cells to scale the features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExX5Akz0UnE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scalardef get_scal(feature):\n",
        "\n",
        "def get_scal(feature):\n",
        "  def minmax(x):\n",
        "    mini = train[feature].min()\n",
        "    maxi = train[feature].max()\n",
        "    return (x - mini)/(maxi-mini)\n",
        "  return(minmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzqcddUQUnKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#All numeric features -scaling\n",
        "\n",
        "feature_columns = []\n",
        "for header in num_c:\n",
        "  scal_input_fn = get_scal(header)\n",
        "  feature_columns.append(feature_column.numeric_column(header, normalizer_fn=scal_input_fn))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYUpUZvgwrPe",
        "colab_type": "text"
      },
      "source": [
        "### Categorical Feature\n",
        "In this dataset, 'ocean_proximity' is represented as a string.  We cannot feed strings directly to a model. Instead, we must first map them to numeric values. The categorical vocabulary columns provide a way to represent strings as a one-hot vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZnlnFZkyEbe",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   Create a categorical feature using 'ocean_proximity'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FIy0sWOy1cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO - YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cf6SoFTUnc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "for feature_name in cat_i_c:\n",
        "  vocabulary = dataframe[feature_name].unique()\n",
        "  cat_c = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
        "  one_hot = feature_column.indicator_column(cat_c)\n",
        "  feature_columns.append(one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnGyWaijzShj",
        "colab_type": "text"
      },
      "source": [
        "### Bucketized Feature\n",
        "\n",
        "Often, you don't want to feed a number directly into the model, but instead split its value into different categories based on numerical ranges. Consider our raw data that represents a homes' age. Instead of representing the house age as a numeric column, we could split the hoome age into several buckets using a [bucketized column](https://www.tensorflow.org/api_docs/python/tf/feature_column/bucketized_column). Notice the one-hot values below describe which age range each row matches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZRlFyP7fOw-",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   Create a Bucketized column using 'housing_median_age'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5w_fqeU0DdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO - YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB-yiVLmUnXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "Age = feature_column.numeric_column(\"housing_median_age\")\n",
        "\n",
        "# bucketized cols\n",
        "age_buckets = feature_column.bucketized_column(Age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
        "feature_columns.append(age_buckets)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri4_wssOg943",
        "colab_type": "text"
      },
      "source": [
        "### Feature Cross\n",
        "\n",
        "Combining features into a single feature, better known as [feature crosses](https://developers.google.com/machine-learning/glossary/#feature_cross), enables a model to learn separate weights for each combination of features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6HHJl3J0j0T",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   Create a Feature Cross of  'housing_median_age' and 'ocean_proximity'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UpZGNHR02Bs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO - YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVLnG0WbUnkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "vocabulary = dataframe['ocean_proximity'].unique()\n",
        "ocean_proximity = tf.feature_column.categorical_column_with_vocabulary_list('ocean_proximity', vocabulary)\n",
        "\n",
        "crossed_feature = feature_column.crossed_column([age_buckets, ocean_proximity], hash_bucket_size=1000)\n",
        "crossed_feature = feature_column.indicator_column(crossed_feature)\n",
        "feature_columns.append(crossed_feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiz6HCWg1CXO",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the cell to determine the number of feature columns you now have.  Compare this number to the previous number of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P3Ewc3_Unsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Total number of feature coumns: ',len(feature_columns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNr00mP41sJp",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the cell to compile, create, and train the Keras model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7n-jl721Tc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dwal3oxUoCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION\n",
        "\n",
        "#Model create\n",
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  layers.Dense(12,  input_dim=8, activation='relu'),\n",
        "  layers.Dense(8, activation='relu'),\n",
        "  layers.Dense(1, activation='linear',  name='median_house_value')\n",
        "])\n",
        "\n",
        "#Model compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['mse'])  \n",
        "\n",
        "### Model Fit\n",
        "history = model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LdUQszM16Oj",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:   **RUN** the next two cells to show loss and accuracy and to plot the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtFSpkd9UoAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8kWMa6xUn-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot\n",
        "import matplotlib.pyplot as plt\n",
        "nrows = 1\n",
        "ncols = 2\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "for idx, key in enumerate(['loss', 'mse']):  \n",
        "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
        "    plt.plot(history.history[key])\n",
        "    plt.plot(history.history['val_{}'.format(key)])\n",
        "    plt.title('model {}'.format(key))\n",
        "    plt.ylabel(key)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4tWwOQt2e-P",
        "colab_type": "text"
      },
      "source": [
        "#### **Exercise**:  Create a prediction model.  Note:  You may use the same values from the previous prediciton.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5RBF38Y272e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuhMkcjisM_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prediction model:  Pass in the features from one row of the test data.\n",
        "\n",
        "#Copy of first line from my test.csv: \n",
        "#-121.86\t39.78\t12.0\t7653.0\t1578.0\t3628.0\t1494.0\t3.0905\t117800.0\tINLAND\n",
        "\n",
        "#This example shows median house value of $117,800 for INLAND property, prediciton is $183,504\n",
        "\n",
        "model.predict({\n",
        "    'longitude': tf.convert_to_tensor([-121.86]),\n",
        "    'latitude': tf.convert_to_tensor([39.78]),\n",
        "    'housing_median_age': tf.convert_to_tensor([12.0]), \t\t\n",
        "    'total_rooms': tf.convert_to_tensor([7653.0]),\n",
        "    'total_bedrooms': tf.convert_to_tensor([1578.0]),  \n",
        "    'population': tf.convert_to_tensor([3628.0]),\n",
        "    'households': tf.convert_to_tensor([1494.0]),\t\n",
        "    'median_income': tf.convert_to_tensor([3.0905]),\n",
        "    'ocean_proximity': tf.convert_to_tensor(['INLAND'])\n",
        "    \n",
        "}, steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PyZLT_ZUn3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SOLUTION - NEAR OCEAN:  Median_house_value is $249,000, prediction is $234,000\n",
        "\n",
        "model.predict({\n",
        "    'longitude': tf.convert_to_tensor([-122.43]),\n",
        "    'latitude': tf.convert_to_tensor([37.63]),\n",
        "    'housing_median_age': tf.convert_to_tensor([34.0]), \t\t\n",
        "    'total_rooms': tf.convert_to_tensor([4135.0]),\n",
        "    'total_bedrooms': tf.convert_to_tensor([687.0]),  \n",
        "    'population': tf.convert_to_tensor([2154.0]),\n",
        "    'households': tf.convert_to_tensor([742.0\t]),\t\n",
        "    'median_income': tf.convert_to_tensor([ 4.9732]),\n",
        "    'ocean_proximity': tf.convert_to_tensor(['NEAR OCEAN'])\n",
        "    \n",
        "}, steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcbdA3arXkej",
        "colab_type": "text"
      },
      "source": [
        "### Analysis \n",
        "\n",
        "The array returns a predicted value.  Compare this value to the test set you ran earlier. Your predicted value may be a bit better.\n",
        "\n",
        "Now that you have your \"feature engineering template\" setup, you can experiment by creating additional features.  For exmample, you can create derived features, such as households per population, and see how they impact the model.  You can also experiment with replacing the features you used to create the feature cross.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R42I8BvbuN7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}